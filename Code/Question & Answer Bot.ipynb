{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52824b89-532a-4e54-87e9-1410813cd39e",
   "metadata": {},
   "source": [
    "# LangChain: Q&A over Documents\n",
    "\n",
    "An example might be a tool that would allow you to query a product catalog for items of interest. The following slide goes through an overview of the flow of loading a document into a vector database for it to be queried by an LLM. \n",
    "\n",
    "![image1.png](..\\Img\\qna_1.png)\n",
    "![image2.png](..\\Img\\qna_2.png)\n",
    "![image3.png](..\\Img\\qna_3.png)\n",
    "\n",
    "## 1. Download required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10c1f7b9",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (0.3.14)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from langchain) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from langchain) (3.11.11)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from langchain) (0.3.29)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from langchain) (0.3.5)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.17 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from langchain) (0.2.10)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from langchain) (2.2.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from langchain) (2.10.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.13)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain) (3.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d43b48",
   "metadata": {},
   "source": [
    "## 2. Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead635a0-42e2-46cc-a9f7-98419eceae6d",
   "metadata": {},
   "source": [
    "Note: LLM's do not always produce the same results. When executing the code in your notebook, you may get slightly different answers that those in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc533037-0b8c-4995-96a3-45b35fa13c18",
   "metadata": {
    "height": 251
   },
   "outputs": [],
   "source": [
    "# account for deprecation of LLM model\n",
    "import datetime\n",
    "# Get the current date\n",
    "current_date = datetime.datetime.now().date()\n",
    "\n",
    "# Define the date after which the model should be set to \"gpt-3.5-turbo\"\n",
    "target_date = datetime.date(2024, 6, 12)\n",
    "\n",
    "# Set the model variable based on the current date\n",
    "if current_date > target_date:\n",
    "    llm_model = \"gpt-3.5-turbo\"\n",
    "else:\n",
    "    llm_model = \"gpt-3.5-turbo-0301\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f5f731",
   "metadata": {},
   "source": [
    "`RetrievalQA` will carry out the retrieval over the specified documents.  <br /> \n",
    "`CSVLoader` is a document loader which will be used to import proprietary data.  <br /> \n",
    "`DocArrayInMemorySearch` is a Vector Store which is an in-memory vector store and does not require connecting to any external Database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "974acf8e-8f88-42de-88f8-40a82cb58e8b",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from IPython.display import display, Markdown\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1e8b48",
   "metadata": {},
   "source": [
    "## 3. Load Data\n",
    "Here, we load our simulated proprietary data (CSV dataset). We will combine this with our language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7249846e",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "file = r\"..\\Data\\OutdoorClothingCatalog_1000.csv\"\n",
    "\n",
    "# Initialize loader\n",
    "loader = CSVLoader(file_path=file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cb14ae",
   "metadata": {},
   "source": [
    "## 4. Create Vector Store\n",
    "\n",
    "Here, we import an index for the Vector Store. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bfaba30",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "from langchain.indexes import VectorstoreIndexCreator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b5ab657",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting docarray\n",
      "  Downloading docarray-0.40.0-py3-none-any.whl.metadata (36 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from docarray) (2.2.1)\n",
      "Requirement already satisfied: orjson>=3.8.2 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from docarray) (3.10.13)\n",
      "Requirement already satisfied: pydantic>=1.10.8 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from docarray) (2.10.4)\n",
      "Collecting rich>=13.1.0 (from docarray)\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting types-requests>=2.28.11.6 (from docarray)\n",
      "  Downloading types_requests-2.32.0.20241016-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from docarray) (0.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from pydantic>=1.10.8->docarray) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from pydantic>=1.10.8->docarray) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from pydantic>=1.10.8->docarray) (4.12.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=13.1.0->docarray)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from rich>=13.1.0->docarray) (2.19.1)\n",
      "Requirement already satisfied: urllib3>=2 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from types-requests>=2.28.11.6->docarray) (2.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\langchain\\lib\\site-packages (from typing-inspect>=0.8.0->docarray) (1.0.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=13.1.0->docarray)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading docarray-0.40.0-py3-none-any.whl (270 kB)\n",
      "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading types_requests-2.32.0.20241016-py3-none-any.whl (15 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: types-requests, mdurl, markdown-it-py, rich, docarray\n",
      "Successfully installed docarray-0.40.0 markdown-it-py-3.0.0 mdurl-0.1.2 rich-13.9.4 types-requests-2.32.0.20241016\n"
     ]
    }
   ],
   "source": [
    "!pip install docarray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4a570d",
   "metadata": {},
   "source": [
    "In order for the index to work, we need to specify the `OpenAIEmbedding` in the `embedding` parameter. \n",
    "\n",
    "As seen below, we have specified `DocArrayInMemorySearch` as our selected vector store, loaded the data and created the vector store. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e200726",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rg255041\\AppData\\Local\\Temp\\ipykernel_46144\\646728540.py:4: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings()\n",
      "c:\\Users\\rg255041\\AppData\\Local\\anaconda3\\envs\\Langchain\\Lib\\site-packages\\pydantic\\_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
      "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# Instantiating embeddings model \n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "index = VectorstoreIndexCreator(\n",
    "    embedding=embeddings,\n",
    "    vectorstore_cls=DocArrayInMemorySearch\n",
    ").from_loaders([loader])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72ee813",
   "metadata": {},
   "source": [
    "Test the connectivity to the Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34562d81",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "query =\"Please list all your shirts with sun protection \\\n",
    "in a table in markdown and summarize each one.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a4c615-d6e4-4dd6-bc53-a9c46df7276c",
   "metadata": {},
   "source": [
    "**Note**:\n",
    "- The notebook uses `langchain==0.0.179` and `openai==0.27.7`\n",
    "- For these library versions, `VectorstoreIndexCreator` uses `text-davinci-003` as the base model, which has been deprecated since 1 January 2024.\n",
    "- The replacement model, `gpt-3.5-turbo-instruct` will be used instead for the `query`.\n",
    "- The `response` format might be different than the video because of this replacement model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cfd0cc37",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "llm_replacement_model = OpenAI(temperature=0, \n",
    "                               model='gpt-3.5-turbo-instruct')\n",
    "\n",
    "response = index.query(query, \n",
    "                       llm = llm_replacement_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae21f1ff",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "| Name | Description | Sun Protection Rating |\n",
       "| --- | --- | --- |\n",
       "| Men's Tropical Plaid Short-Sleeve Shirt | Made of 100% polyester, UPF 50+ rating, wrinkle-resistant, front and back cape venting, two front bellows pockets, imported | SPF 50+, blocks 98% of harmful UV rays |\n",
       "| Men's Plaid Tropic Shirt, Short-Sleeve | Made of 52% polyester and 48% nylon, UPF 50+ rating, SunSmart technology, wrinkle-free, front and back cape venting, two front bellows pockets, imported | SPF 50+, blocks 98% of harmful UV rays |\n",
       "| Men's TropicVibe Shirt, Short-Sleeve | Made of 71% nylon and 29% polyester, UPF 50+ rating, wrinkle-resistant, front and back cape venting, two front bellows pockets, imported | SPF 50+, blocks 98% of harmful UV rays |\n",
       "| Sun Shield Shirt | Made of 78% nylon and 22% Lycra Xtra Life fiber, UPF 50+ rating, moisture-wicking, fits over swimsuit, abrasion-resistant, imported | SPF "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2534597e-4b0c-4563-a208-e2dd91064438",
   "metadata": {},
   "source": [
    "## 5. Breaking Down LangChain \n",
    "\n",
    "### 5A. Query the CSV with a vector database using similarity search\n",
    "\n",
    "The following lines of code breaks down what is going on under the hood of the above functions. \n",
    "\n",
    "First we start with the data load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "631396c6",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import CSVLoader\n",
    "loader = CSVLoader(file_path=file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf8de21",
   "metadata": {},
   "source": [
    "Here, we can start loading documents. When we load the document, we can see that each document corresponds to one of the products in the CSV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6c2164b5",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': '..\\\\Data\\\\OutdoorClothingCatalog_1000.csv', 'row': 0}, page_content=\": 0\\nname: Women's Campside Oxfords\\ndescription: This ultracomfortable lace-to-toe Oxford boasts a super-soft canvas, thick cushioning, and quality construction for a broken-in feel from the first time you put them on. \\n\\nSize & Fit: Order regular shoe size. For half sizes not offered, order up to next whole size. \\n\\nSpecs: Approx. weight: 1 lb.1 oz. per pair. \\n\\nConstruction: Soft canvas material for a broken-in feel and look. Comfortable EVA innersole with Cleansport NXT® antimicrobial odor control. Vintage hunt, fish and camping motif on innersole. Moderate arch contour of innersole. EVA foam midsole for cushioning and support. Chain-tread-inspired molded rubber outsole with modified chain-tread pattern. Imported. \\n\\nQuestions? Please contact us for any inquiries.\")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = loader.load()\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c2a954",
   "metadata": {},
   "source": [
    "As our documents (product desc) is small, we do not need to do text chunking. Thus, here we directly go to the embedding creation. As seen above, `OpenAIEmbeddings` is the OpenAI embedding class used to create the embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e875693a",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2ff937",
   "metadata": {},
   "source": [
    "Here, we can see what happens when we embed our text. This text generates a vector of 1536 elements. Each element is a numerical representation of a portion of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "779bec75",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n",
      "[-0.02196465528695117, 0.006758838256223806, -0.018249490165056663, -0.03923515029463157, -0.014007174091135742]\n"
     ]
    }
   ],
   "source": [
    "embed = embeddings.embed_query(\"Hi my name is Harrison\")\n",
    "\n",
    "print(len(embed))\n",
    "print(embed[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5db573",
   "metadata": {},
   "source": [
    "Here, we create the embeddings for all of the text in the CSV document and store them in a vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "27ad0bb0",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "db = DocArrayInMemorySearch.from_documents(\n",
    "    docs, \n",
    "    embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0329bfd5",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "query = \"Please suggest a shirt with sunblocking\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb02af5",
   "metadata": {},
   "source": [
    "We can now leverage this vector store to find pieces of text similar to an incoming query using the `similarity_search` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7909c6b7",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matching products:  4\n",
      "\n",
      "Sample matching products:\n",
      "  page_content=': 255\n",
      "name: Sun Shield Shirt by\n",
      "description: \"Block the sun, not the fun – our high-performance sun shirt is guaranteed to protect from harmful UV rays. \n",
      "\n",
      "Size & Fit: Slightly Fitted: Softly shapes the body. Falls at hip.\n",
      "\n",
      "Fabric & Care: 78% nylon, 22% Lycra Xtra Life fiber. UPF 50+ rated – the highest rated sun protection possible. Handwash, line dry.\n",
      "\n",
      "Additional Features: Wicks moisture for quick-drying comfort. Fits comfortably over your favorite swimsuit. Abrasion resistant for season after season of wear. Imported.\n",
      "\n",
      "Sun Protection That Won't Wear Off\n",
      "Our high-performance fabric provides SPF 50+ sun protection, blocking 98% of the sun's harmful rays. This fabric is recommended by The Skin Cancer Foundation as an effective UV protectant.' metadata={'source': '..\\\\Data\\\\OutdoorClothingCatalog_1000.csv', 'row': 255}\n"
     ]
    }
   ],
   "source": [
    "docs = db.similarity_search(query)\n",
    "\n",
    "print(\"Number of matching products: \", len(docs))\n",
    "print(\"\\nSample matching products:\\n \", docs[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926c6822",
   "metadata": {},
   "source": [
    "### 5B. Query the CSV with a LLM\n",
    "\n",
    "In order to leverage this for Q&A over the documents, we first need to initialize a retriever. A retriever is a generic way to take in a query and return a document. There are many methods to achieve this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c0c3596e",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dffdd9",
   "metadata": {},
   "source": [
    "Next, we import our language model so that we can have a natural language interface to the above functionality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0625f5e8",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rg255041\\AppData\\Local\\Temp\\ipykernel_46144\\793635378.py:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(temperature = 0.0, model=llm_model)\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(temperature = 0.0, model=llm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88a42c1",
   "metadata": {},
   "source": [
    "Now, we combine the documents into a single piece of text. Here, I have limited it to the first 50 documents so that it fits within the context window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a573f58a",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "loader = CSVLoader(file_path=file)\n",
    "docs = loader.load()\n",
    "docs= docs[:50]\n",
    "\n",
    "qdocs = \"\".join([docs[i].page_content for i in range(len(docs))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8717a9",
   "metadata": {},
   "source": [
    "Pass the text (documents) into the prompt for the LLM to retrieve the necessary products. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "14682d95",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "response = llm.call_as_llm(f\"{qdocs} Question: Please list all your \\\n",
    "shirts with sun protection in a table in markdown and summarize each one.\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8bba545b",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Name                                | Sun Protection | Summary                                                                                                                                                                                                                   |\n",
       "|-------------------------------------|----------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
       "| Refresh Swimwear, V-Neck Tankini Contrasts | UPF 50+ rated | Watersport-ready tankini top made from recycled nylon with Lycra® spandex for stretch. Features lightweight racerback straps, V-neck silhouette, and offers SPF 50+ sun protection. |\n",
       "| Performance Plus Woven Shirt         | SPF 50+        | Breathable summer shirt with quick-dry fabric, moisture-wicking, and abrasion-resistant construction. Provides SPF 50+ sun protection and is ideal for trail or travel.           |\n",
       "| Angler's Athletic Shorts             | UPF 50+ rated | High-performance fly-fishing shorts with quick-drying lightweight fabric, four-way stretch, and active range of motion. Offers SPF 50+ sun protection.                        |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2026c398",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c94d22",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "qa_stuff = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever, \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4769316",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "query =  \"Please list all your shirts with sun protection in a table \\\n",
    "in markdown and summarize each one.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc3c2f3",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "response = qa_stuff.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba1a5db",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500ec062",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "response = index.query(query, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cffb19f",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch,\n",
    "    embedding=embeddings,\n",
    ").from_loaders([loader])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b325340f-26b4-4c7e-81da-da4b895ae058",
   "metadata": {},
   "source": [
    "Reminder: Download your notebook to you local computer to save your work."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
